{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1 of DDM5005\n",
    "Yaowen ZHANG(yaowen.zhang@connect.ust.hk)\n",
    "\n",
    "This tutorial is about basic applications of pytorch. [Pytorch](https://pytorch.org/tutorials/) is a deep learning library developed by Meta AI. It utilizes computational graph and autodiff to build and train the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'device' is where to train the model and load the data. The pytorch has three available device options. \n",
    "\n",
    "GPU and CPU are two most common devices. MPS are designed for mac os. If you have multiple GPUs, you can use the following way to distinguish them, like\n",
    "\n",
    "'cuda:0', 'cuda:1', 'cuda:2'......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.12.1\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('torch version:',torch.__version__)\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concept ###\n",
    "tensor can be seen as a multidimensional array. For instance, vector is a tenor with dimensional 1. Matrix is a tensor with dimensian 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor a: tensor([[1.2631, 0.4896, 0.6071],\n",
      "        [2.2538, 1.4626, 0.8342]])\n",
      "a.shape: torch.Size([2, 3])\n",
      "a.dtype: torch.float32\n",
      "a.device cpu\n",
      "tensor a: tensor([[1.2631, 0.4896, 0.6071],\n",
      "        [2.2538, 1.4626, 0.8342]], dtype=torch.float64)\n",
      "a.dtype: torch.float64\n",
      "a.mean: tensor(-0.3491, dtype=torch.float64) tensor(-0.3491, dtype=torch.float64)\n",
      "a.var: tensor(0.9889, dtype=torch.float64) tensor(0.9889, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3)    \n",
    "# each entry is an normal distribution     \n",
    "print('tensor a:', a)\n",
    "print('a.shape:', a.shape)\n",
    "print('a.dtype:', a.dtype)\n",
    "print('a.device', a.device)\n",
    "a = a.to(torch.float64)\n",
    "print('tensor a:', a)\n",
    "print('a.dtype:', a.dtype)\n",
    "\n",
    "a = torch.randn(2,3, dtype=torch.float64)\n",
    "print('a.mean:', torch.mean(a), a.mean())\n",
    "print('a.var:', torch.var(a), a.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a tensor ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "a.dtype torch.float32\n",
      "a: tensor([[1., 1.],\n",
      "        [1., 1.]], dtype=torch.float16)\n",
      "b: tensor([[0., 0.],\n",
      "        [0., 0.]], dtype=torch.float16)\n",
      "b.shape torch.Size([0])\n",
      "b: tensor([], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# create a tensor with all zero entry\n",
    "a = torch.zeros((2,3))\n",
    "print('a:', a)\n",
    "print('a.dtype', a.dtype)\n",
    "\n",
    "# create a tensor with all one entry\n",
    "a = torch.ones((2, 2), dtype=torch.float16)\n",
    "print('a:', a)\n",
    "\n",
    "b = torch.zeros_like(a)\n",
    "print('b:', b)\n",
    "\n",
    "b = torch.Tensor.new(a)\n",
    "print('b.shape', b.shape)\n",
    "print('b:', b)      # b is empty, but has the same properity as a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "[0.   0.25 0.5  0.75 1.  ]\n",
      "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
      "[0 1 2 3 4]\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "print(b.numpy())\n",
    "\n",
    "a = np.linspace(start=0, stop=1, num=5)\n",
    "print(a)\n",
    "b = torch.linspace(start=0, end=1, steps=5)\n",
    "print(b)\n",
    "a = np.arange(start=0, stop=5)\n",
    "print(a)\n",
    "b = torch.arange(start=0, end=5)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape torch.Size([2, 3]) \n",
      " a: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "a: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "b: tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "b: tensor([[0, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "a: tensor([[0, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[0, 4, 2, 5, 3, 6]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_482661/518492240.py\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print('a.shape', a.shape,'\\n a:', a)\n",
    "b = a.view(3, 2)\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "b[0, 0] = 0\n",
    "print('b:', b)\n",
    "print('a:', a)\n",
    "\n",
    "b= (a.t().contiguous()).view(1, 6)\n",
    "print(b)\n",
    "b = (a.t()).view(1, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'view'ï¼› the two variable shares the same memory. It has the contiguity constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape torch.Size([2, 3]) \n",
      " a: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "a: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "b: tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "b: tensor([[0, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "a: tensor([[0, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "b: tensor([[0, 4, 2, 5, 3, 6]])\n",
      "a: tensor([[0, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "b: tensor([[1, 4, 2, 5, 3, 6]])\n",
      "a: tensor([[0, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print('a.shape', a.shape,'\\n a:', a)\n",
    "b = a.reshape(3, 2)\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "b[0, 0] = 0\n",
    "print('b:', b)\n",
    "print('a:', a)\n",
    "\n",
    "b = (a.t()).reshape(1, 6)\n",
    "print('b:', b)\n",
    "print('a:', a)\n",
    "\n",
    "b[0,0] = 1\n",
    "print('b:', b)\n",
    "print('a:', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## operation ##\n",
    "element-wise product and tensor product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "b: tensor([[1, 1],\n",
      "        [2, 2]])\n",
      "element-wise product:\n",
      " tensor([[1, 2],\n",
      "        [6, 8]])\n",
      "matrix product:\n",
      " tensor([[ 5,  5],\n",
      "        [11, 11]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[1, 1], [2, 2]])\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "print('element-wise product:\\n', a*b)\n",
    "print('matrix product:\\n', torch.matmul(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "broadcast mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2]) torch.Size([2])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) tensor([1, 2])\n",
      "tensor([[1, 4],\n",
      "        [3, 8]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([1, 2])\n",
    "print(a.shape,b.shape)\n",
    "print(a, b)\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min, max, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0787,  1.7426, -0.7115],\n",
      "        [-0.3720,  1.1657,  1.6526]])\n",
      "tensor(1.7426) tensor(1.7426)\n",
      "tensor([-0.2934,  2.9083,  0.9410]) tensor([1.1097, 2.4463])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "print(torch.max(a), a.max())\n",
    "print(a.sum(dim=0), a.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2780, -2.5604,  0.3979],\n",
      "        [-1.2499,  1.0249, -1.0744]])\n",
      "tensor(0.2780)\n",
      "tensor([-1.2499,  1.0249, -1.0744])\n",
      "tensor([ 0.2780, -2.5604,  0.3979, -1.2499,  1.0249, -1.0744])\n",
      "tensor([[[ 0.2780, -2.5604,  0.3979],\n",
      "         [-1.2499,  1.0249, -1.0744]]])\n",
      "tensor([[ 0.2780, -2.5604,  0.3979],\n",
      "        [-1.2499,  1.0249, -1.0744],\n",
      "        [ 1.4849, -0.8208,  0.7947]])\n",
      "tensor([[ 0.2780, -2.5604,  0.3979],\n",
      "        [-1.2499,  1.0249, -1.0744],\n",
      "        [ 1.4849, -0.8208,  0.7947],\n",
      "        [ 1.4849, -0.8208,  0.7947]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "print(a[0, 0])\n",
    "print(a[1,:])\n",
    "print(a.reshape(-1))              # flatten the tensor\n",
    "print(a.reshape(1, 2, 3))         # add dimension\n",
    "\n",
    "b = torch.randn(1, 3)\n",
    "print(torch.cat((a, b), dim=0))\n",
    "print(torch.cat((a, b, b), dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy problem ##\n",
    "The key is to see whether a new memory is created and assigned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([3]) tensor([1, 2, 3])\n",
      "tensor([0, 2, 3])\n",
      "tensor([[0, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(a.shape, a)\n",
    "b = a[0,:]\n",
    "print(b.shape, b)\n",
    "b[0] = 0\n",
    "print(b)\n",
    "print(a)\n",
    "# shallow copy, a and b share the same memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([3]) tensor([1, 2, 3])\n",
      "tensor([0, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(a.shape, a)\n",
    "b = a[0,:].clone()\n",
    "print(b.shape, b)\n",
    "b[0] = 0\n",
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place operation is an operation that changes directly the content of a given linear algebra, vector, matrices(Tensor) without making a copy.\n",
    "\n",
    "avoid inplace operation in pytorch since it will break the computation graph, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "from torch import autograd\n",
    "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32,  requires_grad=True)\n",
    "y = torch.sum(a)\n",
    "\n",
    "grads = autograd.grad(outputs=y, inputs=a)[0]\n",
    "print(grads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inplace operation to replace one entery of a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a view of a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_482661/3682856214.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a view of a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32,  requires_grad=True)\n",
    "a[0, 0] = 0\n",
    "y = torch.sum(a)\n",
    "\n",
    "grads = autograd.grad(outputs=y, inputs=a)[0]\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32,  requires_grad=True)\n",
    "mask = torch.ones_like(a)\n",
    "mask[0,0] = 0\n",
    "y = torch.sum(a*mask)\n",
    "\n",
    "grads = autograd.grad(outputs=y, inputs=a)[0]\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4]) torch.Size([1]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4)\n",
    "b = torch.randn(1)\n",
    "print(a.shape, b.shape, (a*b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3]) torch.Size([3]) torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, 3)\n",
    "b = torch.randn(3)\n",
    "print(a.shape, b.shape, (a*b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_482661/2627011472.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, 1)\n",
    "b = torch.randn(3,1)\n",
    "print(a.shape, b.shape, (a*b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 1]) torch.Size([3, 1, 1]) torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, 4, 1)\n",
    "b = torch.randn(3, 1, 1)\n",
    "print(a.shape, b.shape, (a*b).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation and Transpose ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n",
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, 3, 2)\n",
    "print(a.shape)\n",
    "\n",
    "print(a.permute(1, 2, 0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([1, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "print(a.transpose(0,1).shape)\n",
    "\n",
    "a = torch.randn(1, 2, 3, 4 )\n",
    "print(a.transpose(1,3).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Matrix ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identity matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.eye(3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diagonal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0],\n",
      "        [0, 2, 0, 0],\n",
      "        [0, 0, 3, 0],\n",
      "        [0, 0, 0, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3, 4])\n",
    "print(torch.diag(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.triu() return the upper triangular matrix\n",
    "torch.tril() return the lower triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6811,  0.0451, -2.2809, -0.2531],\n",
      "        [ 2.6170, -0.4712,  1.1841, -0.9455],\n",
      "        [-0.6117,  0.1086, -0.1518,  0.3432],\n",
      "        [-0.9744,  0.1601, -0.2506, -1.2778]])\n",
      "tensor([[-0.6811,  0.0451, -2.2809, -0.2531],\n",
      "        [ 0.0000, -0.4712,  1.1841, -0.9455],\n",
      "        [ 0.0000,  0.0000, -0.1518,  0.3432],\n",
      "        [ 0.0000,  0.0000,  0.0000, -1.2778]])\n",
      "tensor([[ 0.0000,  0.0451, -2.2809, -0.2531],\n",
      "        [ 0.0000,  0.0000,  1.1841, -0.9455],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.3432],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[ 0.0000,  0.0000, -2.2809, -0.2531],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.9455],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[-0.6811,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.6170, -0.4712,  0.0000,  0.0000],\n",
      "        [-0.6117,  0.1086, -0.1518,  0.0000],\n",
      "        [-0.9744,  0.1601, -0.2506, -1.2778]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, 4)\n",
    "print(a)\n",
    "print(a.triu())\n",
    "print(a.triu( diagonal=1))\n",
    "print(a.triu( diagonal=2))\n",
    "print(a.tril())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
