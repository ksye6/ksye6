# -*- coding: utf-8 -*-
"""5005API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GCbSGbUZ25Vc0irPf6uCt_QiKbex9Nfw
"""

import requests
import json

# API doc: https://data.gov.hk/sc/
# using the requests library to make a GET request
url = "https://api.data.gov.hk/v1/nearest-schools"
params = {"lat": "22.3", "long": "114.2", max: 5}
r = requests.get(url, params=params)
print(r.status_code) # https://en.wikipedia.org/wiki/List_of_HTTP_status_codes
print(r.json()) # https://www.json.org/json-en.html

url = "https://api.data.gov.hk/v1/historical-archive/list-files"
params = {"start": "20190101", "end": "20210102", "category": "population", "filetype": "csv", "max": 5}
r = requests.get(url, params=params)
result = r.json()
for file in result["files"]:
    print(file["resource-name-tc"])
    print(file["url"])

url = 'http://www.baiduuuuu.com'
r = requests.get(url)


## r.test contains the HTTP response content body in a textual form
print(r.text)
## Which HTTP status code did we get back from the server?
print(r.status_code)
## What is the textual status code?
print(r.reason)
## What were the HTTP response headers?
print(r.headers)
## The request information is saved as a Python object in r.request:
print(r.request)
## What were the HTTP request headers?
print(r.request.headers)

from bs4 import BeautifulSoup
import matplotlib.pyplot as plt

# how to use BeautifulSoup to parse HTML
url = 'https://en.wikipedia.org/w/index.php' + \
'?title=List_of_Game_of_Thrones_episodes&oldid=802553687'
r = requests.get(url)
html_contents = r.text
#html_soup = BeautifulSoup(html_contents)
html_soup = BeautifulSoup(html_contents, 'html.parser')

"""```html
<h1 id="firstHeading" class="firstHeading mw-first-heading">List of <i>Game of Thrones</i> episodes</h1>
```
"""

###Task 1
## Find the first h1 tag
first_h1 = html_soup.find(name='h1')
print(first_h1.name) # h1
print(first_h1.contents) # ['List of ', [...], ' episodes']
print(str(first_h1))
# Prints out: <h1 class="firstHeading" id="firstHeading" lang="en">List of
# <i>Game of Thrones</i> episodes</h1>
print(first_h1.text) # List of Game of Thrones episodes
print(first_h1.get_text()) # Does the same
print(first_h1.attrs)
# Prints out: {'id': 'firstHeading', 'class': ['firstHeading'], 'lang': 'en'}
print(first_h1.attrs['id']) # firstHeading
print(first_h1['id']) # Does the same
print(first_h1.get('id')) # Does the same
print('------------ CITATIONS ------------')

"""```html
<cite id="CITEREFFowler2011" class="citation web cs1">Fowler, Matt (April 8, 2011). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20120817073932/http://tv.ign.com/articles/116/1160215p1.html">"Game of Thrones: "Winter is Coming" Review"</a>. <a href="/wiki/IGN" title="IGN">IGN</a>. Archived from <a rel="nofollow" class="external text" href="http://tv.ign.com/articles/116/1160215p1.html">the original</a> on August 17, 2012<span class="reference-accessdate">. Retrieved <span class="nowrap">September 22,</span> 2016</span>.</cite>
```
"""

#### Task 2
## Find the first five cite elements with a citation class
cites = html_soup.find_all('cite', class_='citation', limit=5)
for citation in cites:
   print('    ', citation.get_text())
   # Inside of this cite element, find the first a tag
   link = citation.find('a')
   # ... and show its URL
   print(link.get('href'))
print()

"""# Table elements


![image.png](attachment:image.png)
"""

## Task 3
# We'll use a list to store our episode list
episodes = []
#ep_tables = html_soup.find_all('table', class_='wikiepisodetable',limit=3)
ep_tables = html_soup.find_all('table', class_='wikiepisodetable')
for table in ep_tables:
    headers = []
#    rows = table.find_all('tr')
    # Start by fetching the header cells from the first row to determine
    # the field names
    for header in table.find('tr').find_all('th'):
        headers.append(header.text)
    # Then go through all the rows except the first one
    for row in table.find_all('tr')[1:]:
        values = []
        # And get the column cells, the first one being inside a th-tag
        # find 'th' or 'td'
        for col in row.find_all(['th','td']):
            values.append(col.text)
        if values:
            episode_dict = {headers[i]: values[i] for i in range(len(values))}
            episodes.append(episode_dict)
viewer=[]
# Show the results
for episode in episodes:
    b=episode['U.S. viewers(millions)']
    viewer.append(float(b[0:4]))
    print(episode)
plt.title('U.S. viewers(millions)')
plt.plot(viewer,'*')

import pandas as pd
episodes = pd.DataFrame(episodes)
print(episodes)

# pretend to be a browser
r = requests.get('https://www.douban.com/', headers={'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit'})
r.text

# using the requests library to make a post request
url = "https://httpbin.org/post"
data = {"key": "value", "abc": "xyz"}
r = requests.post(url, data=data)
print(r.text)
print(r.json())





